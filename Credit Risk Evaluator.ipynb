{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_X = train_df.drop('loan_status', axis=1)\n",
    "\n",
    "# for column in train_X.columns:\n",
    "#     train_X[column] = LabelEncoder().fit_transform(train_df[column])\n",
    "\n",
    "train_X = train_X.apply(LabelEncoder().fit_transform)\n",
    "# train_X = pd.get_dummies(train_X)\n",
    "\n",
    "train_y = LabelEncoder().fit_transform(train_df['loan_status'])\n",
    "# train_y = pd.get_dummies(train_df['loan_status'])\n",
    "\n",
    "# train_X\n",
    "# train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_X = test_df.drop('loan_status', axis=1)\n",
    "\n",
    "# for column in test_X.columns:\n",
    "#     test_X[column] = LabelEncoder().fit_transform(test_df[column])\n",
    "\n",
    "test_X = test_X.apply(LabelEncoder().fit_transform)\n",
    "# test_X = pd.get_dummies(test_X)\n",
    "\n",
    "test_y = LabelEncoder().fit_transform(test_df['loan_status'])\n",
    "# test_y = pd.get_dummies(test_df['loan_status'])\n",
    "\n",
    "# test_X\n",
    "# test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds which column needs to be added to which dataset\n",
    "\n",
    "# train_columns = train_X.columns.tolist()\n",
    "# test_columns = test_X.columns.tolist()\n",
    "\n",
    "# extra_columns = []\n",
    "\n",
    "# if train_columns > test_columns:\n",
    "#     for column_a in train_columns:\n",
    "#         found = False\n",
    "#         for column_b in test_columns:\n",
    "#             if column_a == column_b:\n",
    "#                 found = True\n",
    "#         if found == False:\n",
    "#             extra_columns.append(column_a)\n",
    "#             print(f'{column_a} needs to be added to the test set!')\n",
    "\n",
    "# else:\n",
    "#     for column_a in test_columns:\n",
    "#         found = False\n",
    "#         for column_b in train_columns:\n",
    "#             if column_a == column_b:\n",
    "#                 found = True\n",
    "#         if found == False:\n",
    "#             extra_columns.append(column_a)\n",
    "            \n",
    "#             print(f'{column_a} needs to be added to the train set!')\n",
    "\n",
    "# if len(extra_columns) == 0:\n",
    "#     print(\"The data is ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing dummy variables to testing set\n",
    "# dummy_column = []\n",
    "\n",
    "# for x in range(len(test_X['index'])):\n",
    "#     dummy_column.append(0)\n",
    "\n",
    "# for column in extra_columns:\n",
    "#     test_X[column] = dummy_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_columns = train_X.columns.tolist()\n",
    "# test_columns = test_X.columns.tolist()\n",
    "\n",
    "# extra_columns = []\n",
    "\n",
    "# if train_columns > test_columns:\n",
    "#     for column_a in train_columns:\n",
    "#         found = False\n",
    "#         for column_b in test_columns:\n",
    "#             if column_a == column_b:\n",
    "#                 found = True\n",
    "#         if found == False:\n",
    "#             extra_columns.append(column_a)\n",
    "#             print(f'{column_a} needs to be added to the test set!')\n",
    "\n",
    "# else:\n",
    "#     for column_a in test_columns:\n",
    "#         found = False\n",
    "#         for column_b in train_columns:\n",
    "#             if column_a == column_b:\n",
    "#                 found = True\n",
    "#         if found == False:\n",
    "#             extra_columns.append(column_a)\n",
    "#             print(f'{column_a} needs to be added to the train set!')\n",
    "\n",
    "# if len(extra_columns) == 0:\n",
    "#     print(\"The data is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION\n",
    "\n",
    "#I predict that the random forests will perform better since the data has not been scaled yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7360426929392446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irish\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "print(f'Training Data Score: {classifier.score(train_X, train_y)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(train_X, train_y)\n",
    "print(f'Training Score: {clf.score(train_X, train_y)}')\n",
    "# print(f'Testing Score: {clf.score(test_X, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(train_X)\n",
    "train_X_scaled = scaler.transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREDICTION\n",
    "\n",
    "#I predict that now that the data has been scaled, the logistic regression model will perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7553366174055829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irish\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(f'Training Data Score: {classifier.score(train_X_scaled, train_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(train_X_scaled, train_y)\n",
    "print(f'Training Score: {clf.score(train_X_scaled, train_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCLUSION\n",
    "\n",
    "#While the logistic regression score changed after scaling the data, the random forest score remained the same.\n",
    "#I'm unsure if this is due to something in the data or if I wrote the code incorrectly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
